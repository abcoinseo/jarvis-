<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AB Siddik's Jarvis - Voice & Visual Only</title>
    <style>
        /* Resetting default styles */
        body, html {
            margin: 0;
            padding: 0;
            height: 100%;
            overflow: hidden; /* Prevents scrollbars */
        }

        body {
            background-color: #000; /* Dark Background */
            color: #0A84FF; /* Cool Blue Text */
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; /* Modern font */
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            text-align: center;
            /* Grid background */
            background-image: linear-gradient(to right, rgba(10, 132, 255, 0.1) 1px, transparent 1px),
                              linear-gradient(to bottom, rgba(10, 132, 255, 0.1) 1px, transparent 1px);
            background-size: 20px 20px; /* Adjust grid size as needed */
        }

        #jarvis-container {
            /* Take up full screen */
            width: 100vw;
            height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }

        /* Listening Indicator (Central Circle) */
        #listening-indicator {
            width: 150px; /* Adjust size as needed */
            height: 150px;
            border-radius: 50%;
            border: 2px solid #0A84FF;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            position: relative; /* For absolute positioning of bars */
            margin-bottom: 20px;
        }

        /* Waveform Bars */
        .waveform-bar {
            width: 4px;
            background-color: #0A84FF;
            margin: 0 2px;
            height: 2px; /* Initial height */
            transform-origin: bottom;
        }

        /* Arrange bars horizontally */
        #waveform-container {
            display: flex;
            justify-content: center;
            align-items: center;
            margin-top: 5px; /* Space between bars and "Listening" text */
        }

        /* "Listening" Text */
        #listening-text {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            font-size: 0.8em;
            letter-spacing: 1px;
            text-transform: uppercase;
        }
    </style>
</head>
<body>

    <div id="jarvis-container">
        <div id="listening-indicator">
            <div id="waveform-container">
                <div class="waveform-bar"></div>
                <div class="waveform-bar"></div>
                <div class="waveform-bar"></div>
                <div class="waveform-bar"></div>
                <div class="waveform-bar"></div>
                <div class="waveform-bar"></div>
                <div class="waveform-bar"></div>
                <div class="waveform-bar"></div>
                <div class="waveform-bar"></div>
                <div class="waveform-bar"></div>
            </div>
            <div id="listening-text">Listening</div>
        </div>
    </div>

    <script>
    //Load franc.js
    const script = document.createElement('script');
    script.src = 'https://cdn.jsdelivr.net/npm/franc@6.1.0/franc.min.js';
    document.head.appendChild(script);

   // API Key (NEVER commit this to public repos!)
    const API_KEY = "AIzaSyDyu0thYNv9bhUlpRxxQbWZq59Wfm9ZDGc";
    const GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key=" + API_KEY;

        // DOM Elements
        const listeningIndicator = document.getElementById("listening-indicator");
        const waveformBars = document.querySelectorAll(".waveform-bar");

        // Speech Recognition Setup
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition = null;
        let audioContext = null;
        let analyser = null;

        // Text-to-Speech
        let speechSynth = window.speechSynthesis;

        //Initialize Audio

        function speak(text) {
            if (speechSynth.speaking) {
                speechSynth.cancel();
            }
            let utterThis = new SpeechSynthesisUtterance(text);
            utterThis.pitch = 1;
            utterThis.rate = 1;

            speechSynth.speak(utterThis);
        }

        // Analyze Audio to control the visualy
        function analyzeAudio() {
            if (!audioContext) return;

            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);

            function draw() {
                analyser.getByteFrequencyData(dataArray);

                for (let i = 0; i < waveformBars.length; i++) {
                    const barHeight = dataArray[i % bufferLength] / 2; // Scaling factor
                    waveformBars[i].style.height = `${barHeight}px`;
                }
                requestAnimationFrame(draw);
            }
            draw();
        }

        async function processCommand(command) {

            try {
                const response = await fetch(GEMINI_API_URL, {
                    method: "POST",
                    headers: {
                        "Content-Type": "application/json",
                    },
                    body: JSON.stringify({
                        contents: [{
                            parts: [{ text: command }],
                        }],
                    }),
                });

                if (!response.ok) {
                    throw new Error(`HTTP error! Status: ${response.status}`);
                }

                const data = await response.json();
                console.log("Gemini API Response:", data);

                let jarvisResponseText = "Error: Could not process response.";

                if (data.candidates && data.candidates.length > 0 && data.candidates[0].content && data.candidates[0].content.parts && data.candidates[0].content.parts.length > 0) {
                    jarvisResponseText = data.candidates[0].content.parts[0].text;
                }

                speak(jarvisResponseText);

            } catch (error) {
                console.error("Error calling Gemini API:", error);
                speak(`Error: ${error.message}`);
            }
        }

        // Language Detection and Command Processing
        async function detectAndProcess(command) {

            try {
                const detectedLangCode = franc(command, {minLength: 3}); //franc detect
            } catch (error) {
                console.error("Language detection error:", error);
                processCommand(command); // Fallback to English
            }
            processCommand(command);
        }

        if (SpeechRecognition) {

            recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = false;
            recognition.maxAlternatives = 1;

            recognition.onstart = function() {
                console.log("Speech recognition started");
                listeningIndicator.style.display = "block";
            };

            recognition.onresult = function(event) {
                const speechResult = event.results[0][0].transcript;
                console.log("Heard: " + speechResult);
                detectAndProcess(speechResult);
            };

            recognition.onspeechend = function() {
                console.log("Speech ended");

            };

            recognition.onerror = function(event) {
                console.error("Speech recognition error:", event.error);
                speak("Sorry, I encountered an error. Please try again.");

            };

            recognition.onend = function() {
                console.log("Speech recognition ended");
                recognition.start();
            };
        } else {

            console.log("Speech recognition is not supported in this browser.");
        }

        // Initilization of audio
        function initializeAudio() {
            try {
                window.AudioContext = window.AudioContext || window.webkitAudioContext;
                audioContext = new AudioContext();
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;

                navigator.mediaDevices.getUserMedia({ audio: true })
                    .then(stream => {
                        const source = audioContext.createMediaStreamSource(stream);
                        source.connect(analyser);
                        analyser.connect(audioContext.destination);
                        analyzeAudio();
                        recognition.start();

                    })
                    .catch(err => {
                        console.error('Error accessing microphone:', err);

                    });
            } catch (e) {
                console.error('Web Audio API is not supported in this browser');
            }
        }
        //Initilize start to audio
        document.addEventListener("DOMContentLoaded", () => {
            initializeAudio();
        });

    </script>
</body>
</html>
